import psycopg2
import sys
import os
import json
from dotenv import load_dotenv
from urllib.parse import urlparse
import openai
import time
import hashlib # For creating a hash of source section keys if needed

# --- Configuration ---
OPENAI_MODEL_NAME = "gpt-4-turbo" # Updated model for generating the top-level summary
MAX_TOKENS_FOR_TOP_LEVEL_SUMMARY_OUTPUT = 700 # Increased for more comprehensive summary
TARGET_FILING_ACCESSION_NUMBER = "0000320193-24-000123" # AAPL example
# Section summaries generated by this model will be used as source
SOURCE_SUMMARIES_MODEL_NAME = "gpt-4-turbo"
# These are the section_key values from sec_section_summaries to use as input
SOURCE_SECTION_KEYS = sorted([
    "Business", 
    "Risk Factors", 
    "MD&A"
])


# --- Load .env and set API Keys & DB URL ---
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DOTENV_PATH = os.path.join(PROJECT_ROOT, '.env')

if os.path.exists(DOTENV_PATH):
    print(f"Loading .env file from: {DOTENV_PATH}")
    load_dotenv(dotenv_path=DOTENV_PATH)
else:
    print(f"Warning: .env file not found at {DOTENV_PATH}. Ensure environment variables are set.")

DATABASE_URL = os.getenv("DATABASE_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not DATABASE_URL:
    print("Error: DATABASE_URL not found.")
    sys.exit(1)
if not OPENAI_API_KEY:
    print("Error: OPENAI_API_KEY not found.")
    sys.exit(1)

# --- Database Connection Parameters ---
parsed_url = urlparse(DATABASE_URL.replace("+asyncpg", ""))
conn_params = {
    'dbname': parsed_url.path[1:],
    'user': parsed_url.username,
    'password': parsed_url.password,
    'host': parsed_url.hostname,
    'port': parsed_url.port,
    'sslmode': 'require'
}

# --- Database Helper Functions ---
def create_top_level_summaries_table(cursor):
    # Hash of sorted source section keys can be used for a more robust unique constraint
    # if we want to allow different sets of source sections per filing/model.
    # For simplicity here, the main check will be in the script logic before insertion.
    table_creation_query = """
    CREATE TABLE IF NOT EXISTS sec_filing_top_level_summaries (
        id SERIAL PRIMARY KEY,
        filing_accession_number TEXT NOT NULL REFERENCES sec_filings(accession_number) ON DELETE CASCADE,
        summarization_model_name TEXT NOT NULL,
        source_section_keys TEXT[] NOT NULL, -- Array of section keys used
        source_summaries_concatenated TEXT, -- The actual text fed to the LLM
        top_level_summary_text TEXT NOT NULL,
        generated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        CONSTRAINT uq_filing_model_source_keys UNIQUE (filing_accession_number, summarization_model_name, source_section_keys)
    );
    CREATE INDEX IF NOT EXISTS idx_toplevel_accession_number ON sec_filing_top_level_summaries(filing_accession_number);
    CREATE INDEX IF NOT EXISTS idx_toplevel_model_name ON sec_filing_top_level_summaries(summarization_model_name);
    """
    cursor.execute(table_creation_query)
    print("'sec_filing_top_level_summaries' table checked/created successfully.")

# --- OpenAI Helper Function (similar to summarize_sections.py) ---
def call_openai_api(openai_client_instance, prompt_messages, model_name, max_tokens_output):
    try:
        response = openai_client_instance.chat.completions.create(
            model=model_name,
            messages=prompt_messages,
            max_tokens=max_tokens_output,
            temperature=0.3,
            top_p=1.0,
            frequency_penalty=0.0,
            presence_penalty=0.0
        )
        if response.choices and response.choices[0].message:
            return response.choices[0].message.content.strip()
        else:
            print("Warning: OpenAI API response did not contain expected choices or message content.")
            print(f"Full API Response: {response}")
            return None
    except openai.APIError as e:
        print(f"OpenAI API Error: {e}")
        return None
    except Exception as e:
        print(f"An unexpected error occurred during OpenAI API call: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    print("Starting top-level summary generation process...")
    
    openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
    conn = None
    cur = None

    try:
        conn = psycopg2.connect(**conn_params)
        cur = conn.cursor()
        print(f"Connected to PostgreSQL database '{conn_params['dbname']}'.")

        create_top_level_summaries_table(cur)
        conn.commit()

        # 1. Check for existing top-level summary
        cur.execute(
            """SELECT id FROM sec_filing_top_level_summaries 
               WHERE filing_accession_number = %s AND summarization_model_name = %s AND source_section_keys = %s""",
            (TARGET_FILING_ACCESSION_NUMBER, OPENAI_MODEL_NAME, SOURCE_SECTION_KEYS)
        )
        if cur.fetchone():
            print(f"Top-level summary already exists for {TARGET_FILING_ACCESSION_NUMBER}, model {OPENAI_MODEL_NAME}, and sources {SOURCE_SECTION_KEYS}. Exiting.")
            return

        # 2. Fetch individual section summaries
        print(f"Fetching section summaries for {TARGET_FILING_ACCESSION_NUMBER} from model {SOURCE_SUMMARIES_MODEL_NAME}...")
        fetched_summaries = []
        all_source_summaries_found = True
        for section_key in SOURCE_SECTION_KEYS:
            cur.execute(
                """SELECT summary_text FROM sec_section_summaries
                   WHERE filing_accession_number = %s AND section_key = %s 
                     AND summarization_model_name = %s AND processing_status = 'reduce_complete'""",
                (TARGET_FILING_ACCESSION_NUMBER, section_key, SOURCE_SUMMARIES_MODEL_NAME)
            )
            row = cur.fetchone()
            if row and row[0]:
                fetched_summaries.append({"key": section_key, "summary": row[0]})
                print(f"  Successfully fetched summary for section: {section_key}")
            else:
                print(f"  ERROR: Could not find a 'reduce_complete' summary for section: {section_key} (Filing: {TARGET_FILING_ACCESSION_NUMBER}, Model: {SOURCE_SUMMARIES_MODEL_NAME})")
                all_source_summaries_found = False
                break
        
        if not all_source_summaries_found or not fetched_summaries:
            print("Could not fetch all required source section summaries. Exiting.")
            return
        
        # 3. Format input for LLM
        concatenated_input_for_llm = ""
        for item in fetched_summaries:
            concatenated_input_for_llm += f"Section: {item['key']}\nSummary:\n{item['summary']}\n\n---\n\n"
        
        print(f"\nConcatenated input for LLM prepared ({len(concatenated_input_for_llm)} chars). First 500 chars:")
        print(concatenated_input_for_llm[:500] + "...")

        # 4. Call LLM
        system_prompt_content = "You are an expert financial analyst AI. Your task is to synthesize information from provided SEC 10-K section summaries into a comprehensive analysis tailored for hedge fund managers to aid in their investment decisions."
        
        user_prompt_content = f"""From the following section summaries of an SEC 10-K filing, provide a comprehensive analysis for a hedge fund manager. Focus on aspects critical for investment decisions.

Your analysis should cover:
1.  **Overall Sentiment and Key Takeaways:** What is the general outlook (positive, negative, neutral)? What are the 2-3 most critical takeaways a hedge fund manager should know immediately?
2.  **Significant Performance Highlights & Lowlights:** Based on the MD&A, what were notable financial or operational achievements or shortcomings?
3.  **Major Risks & Mitigations (if mentioned):** From Risk Factors, what are the 2-3 most significant risks that could materially impact the company? Are any mitigations discussed?
4.  **Strategic Direction & Business Outlook:** Insights from the Business section regarding strategy, competitive positioning, and future growth drivers or concerns.
5.  **Red Flags or Green Flags:** Identify any specific points that stand out as particularly concerning (red flags) or exceptionally positive (green flags) from an investment perspective.

Present your analysis in clear, concise language. Use bullet points within each numbered section for readability. Ensure your analysis is strictly derived from the provided text and avoids speculation. Cite the source section (e.g., '[Business]', '[Risk Factors]', '[MD&A]') for key pieces of information where appropriate.

Section Summaries:
{concatenated_input_for_llm}"""

        prompt_messages = [
            {"role": "system", "content": system_prompt_content},
            {"role": "user", "content": user_prompt_content}
        ]

        print("\nCalling OpenAI API to generate top-level summary (Hedge Fund Manager focus)...")
        top_level_summary = call_openai_api(openai_client, prompt_messages, OPENAI_MODEL_NAME, MAX_TOKENS_FOR_TOP_LEVEL_SUMMARY_OUTPUT)

        if not top_level_summary:
            print("Failed to generate top-level summary from OpenAI. Exiting.")
            return
        
        print(f"\nSuccessfully generated top-level summary:\n{top_level_summary}")

        # 5. Save result
        print("\nSaving top-level summary to the database...")
        try:
            cur.execute(
                """INSERT INTO sec_filing_top_level_summaries 
                   (filing_accession_number, summarization_model_name, source_section_keys, source_summaries_concatenated, top_level_summary_text)
                   VALUES (%s, %s, %s, %s, %s)""",
                (TARGET_FILING_ACCESSION_NUMBER, OPENAI_MODEL_NAME, SOURCE_SECTION_KEYS, concatenated_input_for_llm, top_level_summary)
            )
            conn.commit()
            print("Top-level summary saved successfully.")
        except psycopg2.Error as db_insert_err:
            print(f"Database error during insert of top-level summary: {db_insert_err}")
            conn.rollback() # Rollback the failed insert

    except psycopg2.Error as db_err:
        print(f"\nDatabase error occurred: {db_err}")
        if conn: conn.rollback()
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if cur: cur.close()
        if conn: conn.close()
        print("\nPostgreSQL connection closed.")

if __name__ == "__main__":
    summarization_dir = os.path.dirname(os.path.abspath(__file__))
    # Ensure project root and .env path are correct relative to this script's location
    # PROJECT_ROOT is already defined above and should be correct.
    if not os.path.exists(DOTENV_PATH):
        # This is an additional check; initial one is at global scope
        print(f"Critical Error: .env file not found at {DOTENV_PATH} before main execution.")
        # sys.exit(1) # Or handle as per preference, main will exit if DB_URL is missing

    main() 